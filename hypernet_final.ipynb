{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYPERNETWORK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTRODUCTIOIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hipernetworki** lub w skrócie **hipernety** to sieci neuronowe, które generują wagi dla innej sieci neuronowej, znanej jako sieć docelowa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kluczowe cechy i zalety hipernetów, które oferują aplikacje w różnych ustawieniach problemów:\n",
    "\n",
    "* Soft weight sharing: Hipernetworki można trenować do generowania wag wielu DNN do rozwiązywania powiązanych zadań.\n",
    "\n",
    "* Dynamic architectures: Hipernetworki mogą być używane do generowania wag sieci o architekturze dynamicznej, w której liczba warstw lub struktura sieci zmienia się podczas szkolenia lub wnioskowania. Może to być szczególnie przydatne w przypadku zadań, w których docelowa struktura sieci nie jest znana w czasie szkolenia.\n",
    "\n",
    "* Data-adaptive DNN: w przeciwieństwie do standardowego DNN, którego wagi są ustalane w czasie wnioskowania, HyperDNN można opracować w celu generowania sieci docelowej dostosowanej do potrzeb danych. W takich przypadkach hipernety są uwarunkowane danymi wejściowymi w celu dostosowania się do danych.\n",
    "\n",
    "* Uncertainty quantification: Hipernety mogą skutecznie trenować DNN ktore świadome o niepewności, wykorzystując techniki jak multiple inputs z rozkładu szumów lub włączenie przerywania w hipernetach sami.\n",
    "\n",
    "* Parameter efficiency: DNN przeszkolony w hipernetach może mieć mniej wag niż\n",
    "standardowe DNNs, powodujące z kompresji wag. Może to być szczególnie przydatne, gdy\n",
    "cos dziala z ograniczonymi zasobami, ograniczonymi danymi lub w przypadku danych o dużych wymiarach i może skutkować szybszy trening niż zlykle DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Main Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Struktura i rola**: Main Network to typowa sieć neuronowa, którą można zaprojektować do dowolnego zadania głębokiego uczenia, takiego jak klasyfikacja obrazu, przetwarzanie języka naturalnego lub inne zadania. Struktura tej sieci może się różnić w zależności od konkretnego zadania: może to być splotowa sieć neuronowa (CNN) do przetwarzania obrazu, powtarzająca się sieć neuronowa (RNN) do przetwarzania sekwencji danych i tak dalej.\n",
    "\n",
    "**Uczenie**: w normalnej sytuacji wagi tej sieci są inicjowane losowo, a następnie optymalizowane w procesie uczenia się, aby rozwiązać dany problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hypernetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Struktura i rola**: Hypernetwork to oddzielna sieć neuronowa, której celem jest generowanie wag dla sieci głównej. Ta sieć jest zwykle mniejsza i może być zaprojektowana tak, aby uwzględniać pewne cechy zadania, do którego szkolona jest sieć główna.\n",
    "\n",
    "**Interakcja z primary network**: Hypernetwork pobiera dane wejściowe, które mogą zawierać informacje o stanie lub strukturze sieci głównej i na podstawie tych danych generuje wagi dla sieci głównej. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ТУТ ВСТАВИТЬ КОД ПЛЮС ЗАДАНИЕ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorisation of Hypernetworks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Istnieje podział na 5 kryteriów projektowania hipersieci:\n",
    "- input-based \n",
    "- output-based\n",
    "- variability of inputs \n",
    "- variability of outputs\n",
    "- architecture-based\n",
    "\n",
    "Za pomocą każdego z nich możemy lepiej zrozumieć działanie konkretnej hipersieci odpowiadając na pytania:\n",
    "\n",
    "![categorisation.png](./imgs/categorisation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input-based hypernetworks\n",
    "\n",
    "Hypernetworki przyjmują wektor kontekstowy jako dane wejściowe i generują wagi docelowej sieci DNN jako wyjście. W zależności od użytego wektora kontekstowego możemy wyróżnić następujące typy hypernetworks:\n",
    "\n",
    "- **Task-conditioned hypernetworks**: Te sieci przyjmują informacje specyficzne dla zadania jako dane wejściowe. Sieć generuje wagi dostosowane do konkretnego zadania, co pozwala na dostosowanie jej zachowania i współdzielenie informacji między zadaniami.\n",
    "\n",
    "- **Data-conditioned hypernetworks**: Te sieci są warunkowane danymi, na których szkolona jest docelowa sieć. Sieć generuje wagi na podstawie charakterystyki danych wejściowych, co pozwala na dynamiczną adaptację modelu do konkretnych wzorców lub cech.\n",
    "\n",
    "- **Noise-conditioned hypernetworks**: Te sieci nie są warunkowane żadnymi danymi wejściowymi ani wskazówkami zadania, a raczej losowo wybranym szumem. Sprawia to, że są bardziej uniwersalne i pomagają w kwantyfikacji niepewności predykcyjnej dla DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output-based Hypernetworks\n",
    "\n",
    "W zależności od sposobu generowania wag, czyli strategii generacji wag, klasyfikujemy hypernetworki na te, które generują wszystkie wagi naraz, i te, które tego nie robią. \n",
    "\n",
    "- **Generate Once**: Te sieci generują wagi całej docelowej sieci DNN naraz. Wszystkie wygenerowane wagi są używane, a wagi każdej warstwy są generowane razem.\n",
    "\n",
    "- **Generate Multiple**: Te sieci mają wiele głów????? do produkcji wag i ta metoda generowania wag może uzupełniać inne podejścia. Upraszcza to złożoność i redukuje liczbę wag wymaganych w ostatniej warstwie hypernetwork przez liczbę głów.\n",
    "\n",
    "- **Generate Chunk-wise**: Sieci tego typu generują wagi docelowej sieci w częściach. Może to prowadzić do niewykorzystania niektórych wygenerowanych wag, ponieważ są one produkowane zgodnie z rozmiarem części, który może nie odpowiadać rozmiarom warstw.\n",
    "\n",
    "- **Generate Component-wise**: Ta strategia na oddzielnym tworzeniu wag dla każdego indywidualnego komponentu modelu docelowego. Jest to pomocne w generowaniu specyficznych wag, ponieważ różne warstwy lub kanały reprezentują różne cechy lub wzorce w sieci. Jednak podobnie jak w podejściu chunk-wise, sieci hypernetwork składowe wymagają osadzenia dla każdego komponentu, aby odróżnić różne komponenty i wytworzyć wagi specyficzne dla danego komponentu. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability of Inputs\n",
    "\n",
    "Możemy kategoryzować hipernety na podstawie zmienności danych wejściowych.\n",
    "\n",
    "- **Static Inputs**: Jeśli Dane wejściowe są predefiniowane i są stałe, hypernet jest nazywany statycznym w odniesieniu do danych wejściowych.\n",
    "\n",
    "\n",
    "- **Dynamic Inputs**: Jeśli Dane wejściowe zmieniają się i generalnie zależą od danych, na których trenowana jest sieć docelowa, następnie hypernet jest nazywany dynamicznym w odniesieniu do danych wejściowych. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variability of Outputs\n",
    "\n",
    "Klasyfikując sieci hypernetwork na podstawie charakterystyki wag sieci docelowej, możemy podzielić je na dwa typy: statyczne i dynamiczne wyjścia.\n",
    "\n",
    "- **Static Outputs**: Jeśli wagi sieci docelowej mają stały rozmiar, to sieć hypernetwork nazywana jest statyczną względem wyjść. W takim przypadku sieć docelowa również jest statyczna.\n",
    "\n",
    "- **Dynamic Outputs**: Jeśli wagi sieci docelowej nie są stałe, architektura zmienia się w zależności od rozmiaru, to sieć hypernetworku nazywana jest dynamiczną względem wyjść, a sieć docelowa również jest siecią dynamiczną, ponieważ może mieć różną architekturę w zależności od wejścia sieci hypernetwork."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamism in Hypernetworks\n",
    "\n",
    "- **Static Hypernets**: Jeśli wejście sieci hypernetwork jest stałe, a liczba wag generowanych przez sieć hypernetwork dla sieci docelowej jest stała, wówczas sieć hypernetwork nazywana jest statyczną.\n",
    "\n",
    "- **Dynamic Hypernets**: Jeśli wejście sieci hypernetwork opiera się na danych wejściowych sieci docelowej lub liczba wag generowanych przez sieć hypernetwork dla sieci docelowej jest zmienna, wówczas sieć hypernetwork nazywana jest dynamiczną."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Architecture of Hypernetworks\n",
    "\n",
    "W klasyfikacji sieci hypernetwork na podstawie ich architektury możemy wyróżnić cztery główne typy:\n",
    "\n",
    "- **MLPs**: Sieci hypernetwork oparte na MLP wykorzystują gęstą i w pełni połączoną architekturę, co pozwala na kompleksowe generowanie wag, biorąc pod uwagę całą informację wejściową.\n",
    "\n",
    "- **CNNs**: Sieci hypernetwork oparte na CNN wykorzystują warstwy konwolucyjne do przechwytywania lokalnych wzorców i informacji przestrzennych, co sprawia, że są one skuteczne w zadaniach związanych z danymi przestrzennymi, takimi jak analiza obrazów czy wideo.\n",
    "\n",
    "- **RNNs**: Sieci hypernetwork oparte na RNN zawierają rekurencyjne połączenia w swojej architekturze, co umożliwia przetwarzanie informacji sekwencyjnych i dynamiczne generowanie wag na podstawie poprzednich stanów lub danych wejściowych, co czyni je odpowiednimi dla zadań związanych z danymi sekwencyjnymi.\n",
    "\n",
    "- **Attention-based hypernetworks**: Sieci hypernetwork oparte na mechanizmach uwagi selektywnie koncentrują się na istotnych cechach wejściowych, generując wagi dla sieci docelowej, co pozwala im uchwycić dalekosiężne zależności i poprawić jakość generowanych wyjść.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
